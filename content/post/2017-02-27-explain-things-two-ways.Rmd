---
date: '2017-02-27'
slug: explain-things-two-ways
title: Explain things two ways
---

Somewhere I remember learning that a good way to help audiences understand things is to explain it two ways. This works most naturally in speech, and I find that getting it into text requires a little more finesse.

Here's an example from my own work. First I'll explain it only one way: "Consumption of antibiotics is one of the main drivers of antibiotic resistance. However, the relationship between consumption and resistance is not well understood."

And now I'll explain it two ways: "Consumption of antibiotics is one of the main drivers of antibiotic resistance. Every time someone takes an antibiotic, there's a chance that they're causing antibiotic resistance. However, the relationship between consumption and resistance is not well understood. We don't know how much resistance comes from each pill we take."

You might say, "But that's cheating! You put in more words and information the second time you explained."

Correct! But I said you should explain it two different _ways_, not two different _times_. (If I could wave a wand and never have someone explain something two me two times but the same way, I would.)

Somehow I remember [this bit](https://www.youtube.com/watch?v=X2wLP0izeJE) by Ira Glass about storytelling. First he plays a version of a radio show he made early in his career:



<blockquote>It's not such a long way from the local grocery store to the international debate over whether sorghum and meat production are causing corn to decline in Latin America. There's a general air of prosperity here, partly thanks to Mexican imports of US grains, which help boost our farm economy. Mexico is now one of our biggest grain customers, buying a half billion to a billion dollars worth every year, including corn to feed its people and sorghum to feed its livestock. This helps cut our trade deficit and helps everyone in the US economy. But in Mexico, this policy has led to fewer tortillas for the poor and unappetizing tortillas for everyone else.</blockquote>



After making many faces, he says that he'll re-explain the story a lot better. Then he says:



<blockquote>Because Mexico produces a lot of stuff that they ship to the United States —tomatoes and all sorts of wonderful food that we eat here— they don't make enough corn for their own people. For us to get really great tomatoes year-round, Mexicans eat worse.</blockquote>



There's a lot to be said for his second version, but I think there's also something to be said for it being the second version. Even if you only understood 20% of his turgid version, you'll get a synergistic benefit from hearing it in a different way.

I was led to think of all this because I just heard something similar happen in [a podcast](http://www.rand.org/multimedia/audio/2016/12/14/the-future-of-artificial-intelligence.html) from the [RAND Corporation](http://www.rand.org/) about artificial intelligence. This was an interesting example because they're talking about machine learning, which I used a fair amount during my graduate work:



<blockquote>_Moderator._ Just like everything else that humans design, the role [...] of the designer gets baked into the product. [...] What does it mean to have bias in AI? [...]

_Panelist._ OK, when we talk about bias, you can think about it from two points of view. [...] AI systems learn from data. Now, is the data wholly objective? Is it a wholly objective representation of the world as it is? That's not always true. When you're learning from data, if you're learning automatically from data, you're basically learning all the biases that are baked into the data.

_Moderator._ Can you give a little bit more context on what you mean by "learn by data"?

_Panelist._ I guess in a supervised learning— or even in an unsupervised learning— but let's stick with supervised learning. In a supervised learning context, you're trying to get an AI system to learn the relationship between the inputs and outputs such that you can forecast for new examples what the output should be. The only way you can do that is inductively from the data you've seen in the past, from past examples. I could go into more detail but it gets more technical at that point.

_Moderator_. So what you're saying is that you're feeding in questions that you know the answer to—

_Panelist_. Exactly.

_Moderator_. —and you're making sure that the algorithm—

_Panelist_. Yes.

_Moderator._ —is making the right decision.

_Panelist_. Yes, and you're tweaking it to make sure it learns, eventually, how to get the right answer on that data.

_Moderator_: And that's what you're referring to as the process of "training".

_Panelist_. Yes, exactly.

_Moderator_. OK, keep going.</blockquote>



I find this exchange remarkable because:





  * the panelist used the terms "supervised learning", "unsupervised learning", "inputs", "outputs", "forecast", "examples", and "inductively" without any definitions, context, or concrete examples


  * the panelist identified the threshold of "more technical" as _after_ all those words


  * the moderator noticed and tried to help the audience out by re-stating the same idea in a way that is much simpler (he uses words like "question" and "answer") and more accessible (he relates "training" the algorithm to the way that, say, a person studies flashcards)


  * the panelist finds this clarification so trivial that he can't help but interrupt multiple times



So this both a case of a curse of knowledge (i.e., the panelist is so expert that he's forgotten that most people don't know what "forecast" means in the context of machine learning) and of telling it two ways. Telling it two ways has become my antidote for the curse of knowledge. I try to that someone who is brilliant enough to piece together what I mean from what I say is listening, and they ask, "Wait, so you're saying that..." Then I answer that question.